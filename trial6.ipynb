{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        The constructor of the Document class, which initializes instance variables.\n",
    "        \"\"\"\n",
    "        self.path = path  # The path of the document\n",
    "        self.bucket_name = \"Name of bucket containing the document is not specified yet!\"  # The bucket name\n",
    "        self.order_num = \"Order number of document is not specified yet!\"  # The order number\n",
    "        self.name = \"Name of document is not specified yet!\"  # The document's name\n",
    "        self.type = self.get_file_extension()  # The type of the document\n",
    "        self.is_analysable = self.is_ocr_analysable()  # Checks whether the document can be analyzed with OCR\n",
    "\n",
    "    def get_file_extension(self):\n",
    "        \"\"\"\n",
    "        Method to get the file extension from the path.\n",
    "        \"\"\"\n",
    "        _, extension = self.path.rsplit('.', 1)  # Split the path by '.' and get the last part\n",
    "        return '.' + extension.lower()  # Return the extension with a '.' prefix and in lower case\n",
    "\n",
    "    def is_ocr_analysable(self):\n",
    "        \"\"\"\n",
    "        Method to check whether the document is analyzable with OCR.\n",
    "        \"\"\"\n",
    "        if self.type == \".pdf\":  # If the document is a PDF\n",
    "            return False  # Return False\n",
    "        elif self.type in [\".jpg\", \".jpeg\", \".png\"]:  # If the document is a JPG, JPEG, or PNG\n",
    "            return True  # Return True\n",
    "        else:\n",
    "            # If the document is not any of the supported types, raise a ValueError\n",
    "            raise ValueError(\"The imported document has an unsupported file format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pdf2image import convert_from_bytes\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, region_name = 'eu-central-1'):\n",
    "        \"\"\"\n",
    "        The constructor of the DocumentProcessor class.\n",
    "        \"\"\"\n",
    "        self.session = boto3.Session(region_name=region_name)  # Create a session with the specified region\n",
    "        self.s3_resource = self.session.resource('s3')  # Create an S3 resource from the session\n",
    "        self.s3_client = self.session.client('s3')  # Create an S3 client from the session\n",
    "        self.textract = self.session.client('textract')  # Create a Textract client from the session\n",
    "\n",
    "    def get_bucket_folder_content(self, folder_path, bucket_name = 'bucket-zakariyae-trial'):\n",
    "        \"\"\"\n",
    "        Method to get the content of a folder in an S3 bucket.\n",
    "        \"\"\"\n",
    "        folder_name = folder_path.rstrip('/').split('/')[-1]  # Extract the folder name from the path\n",
    "\n",
    "        # List the objects in the specified S3 bucket and folder\n",
    "        response = self.s3_client.list_objects_v2(Bucket = bucket_name, Prefix = folder_path)\n",
    "\n",
    "        documents = []  # List to store the documents\n",
    "        if 'Contents' in response:  # If the response contains 'Contents'\n",
    "            for object in response['Contents']:  # For each object in the response\n",
    "                object_key = object['Key']  # Get the object key\n",
    "\n",
    "                if object_key.endswith('/'):  # If the object key is a directory\n",
    "                    continue  # Skip to the next iteration\n",
    "\n",
    "                document = Document(object_key)  # Create a Document instance for the object\n",
    "                document.order_num = folder_name  # Assign the folder name to the order number of the document\n",
    "\n",
    "                # Extract the document name from the object key and assign it to the name of the document\n",
    "                document_name = object_key.rsplit('/', 1)[-1].rsplit('.', 1)[0]\n",
    "                document.name = document_name\n",
    "\n",
    "                document.bucket_name = bucket_name  # Assign the bucket name to the bucket name of the document\n",
    "\n",
    "                documents.append(document)  # Append the document to the list\n",
    "        else:\n",
    "            print('No objects found in the specified bucket and folder.')\n",
    "        return documents  # Return the list of documents\n",
    "\n",
    "    def file_converter(self, document):\n",
    "        \"\"\"\n",
    "        Method to convert a PDF document to PNG images.\n",
    "        \"\"\"\n",
    "        # Fetch the document from the S3 bucket\n",
    "        response = self.s3_client.get_object(Bucket = document.bucket_name, Key = document.path)\n",
    "\n",
    "        # Convert the document to images\n",
    "        images = convert_from_bytes(response['Body'].read())\n",
    "\n",
    "        return images  # Return the images\n",
    "\n",
    "    def analyze_document(self, document):\n",
    "        \"\"\"\n",
    "        Method to analyze a document using AWS Textract.\n",
    "        \"\"\"\n",
    "        if document.type in [\".jpg\", \".jpeg\", \".png\"]:  # If the document is a JPG, JPEG, or PNG\n",
    "            # Analyze the document using AWS Textract\n",
    "            response = self.textract.analyze_document(\n",
    "                Document={'S3Object': {'Bucket': document.bucket_name, 'Name': document.path}},\n",
    "                FeatureTypes=[\"TABLES\", \"FORMS\", \"SIGNATURES\"])\n",
    "            return response  # Return the response\n",
    "\n",
    "        elif document.type == \".pdf\":  # If the document is a PDF\n",
    "            png_files = self.file_converter(document)  # Convert the PDF to PNG images\n",
    "\n",
    "            responses = []  # List to store the responses\n",
    "            for png_file in png_files:  # For each PNG image\n",
    "                byte_stream = io.BytesIO()  # Create a byte stream\n",
    "                png_file.save(byte_stream, format='PNG')  # Save the PNG image to the byte stream\n",
    "                byte_stream = byte_stream.getvalue()  # Get the byte data from the byte stream\n",
    "\n",
    "                # Analyze the PNG image using AWS Textract\n",
    "                response = self.textract.analyze_document(Document={'Bytes': byte_stream}, \n",
    "                                                          FeatureTypes=[\"TABLES\", \"FORMS\", \"SIGNATURES\"])\n",
    "                responses.append(response)  # Append the response to the list\n",
    "\n",
    "            return responses  # Return the list of responses\n",
    "\n",
    "        else:\n",
    "            # If the document is not a supported type, raise a ValueError\n",
    "            raise ValueError(f'The document \"{document.name}\" has an unsupported file format.')\n",
    "    \n",
    "    def extract_data(self, responses):\n",
    "        \"\"\"\n",
    "        Extract data from the response of the AWS Textract API.\n",
    "        \"\"\"\n",
    "        if isinstance(responses, dict):\n",
    "            responses = [responses]  # If there is only one response, convert it to a list for the loop below\n",
    "\n",
    "        tables = []  # List to hold extracted tables\n",
    "        forms = []   # List to hold extracted form key-value pairs\n",
    "        signatures = []  # List to hold extracted signatures\n",
    "        lines = []  # List to hold extracted lines\n",
    "        words = []  # List to hold extracted words\n",
    "\n",
    "        # Loop over each response\n",
    "        for response in responses:\n",
    "            # Iterate through blocks in the response\n",
    "            for block in response['Blocks']:\n",
    "                block_type = block['BlockType']\n",
    "\n",
    "                # Extract tables\n",
    "                if block_type == 'TABLE':\n",
    "                    table = {}  # Dictionary to hold table data\n",
    "                    cells = []  # List to hold cell data\n",
    "\n",
    "                    # Check if block has relationships\n",
    "                    if 'Relationships' in block:\n",
    "                        # Loop over each relationship\n",
    "                        for relationship in block['Relationships']:\n",
    "                            # Check if the relationship is of type 'CHILD'\n",
    "                            if relationship['Type'] == 'CHILD':\n",
    "                                # Loop over each ID in the relationship\n",
    "                                for cell_id in relationship['Ids']:\n",
    "                                    # Find the block with the matching ID\n",
    "                                    cell_block = [b for b in response['Blocks'] if b['Id'] == cell_id][0]\n",
    "                                    # Extract cell data\n",
    "                                    cell = self._extract_cell_data(cell_block, response)\n",
    "                                    # Append cell data to cells list\n",
    "                                    cells.append(cell)\n",
    "                    # Add cells to the table dictionary\n",
    "                    table['Cells'] = cells\n",
    "                    # Append the table to the tables list\n",
    "                    tables.append(table)\n",
    "\n",
    "                # Extract forms (key-value pairs)\n",
    "                elif block_type == 'KEY_VALUE_SET':\n",
    "                    key_value = {}  # Dictionary to hold key-value pair\n",
    "                    # Check if block has entity types\n",
    "                    if 'EntityTypes' in block:\n",
    "                        # Extract keys\n",
    "                        if 'KEY' in block['EntityTypes']:\n",
    "                            key = ''  # String to hold the key\n",
    "                            # Check if block has relationships\n",
    "                            if 'Relationships' in block:\n",
    "                                # Loop over each relationship\n",
    "                                for relationship in block['Relationships']:\n",
    "                                    # Check if the relationship is of type 'CHILD'\n",
    "                                    if relationship['Type'] == 'CHILD':\n",
    "                                        # Loop over each ID in the relationship\n",
    "                                        for word_id in relationship['Ids']:\n",
    "                                            # Find the block with the matching ID\n",
    "                                            word = [b for b in response['Blocks'] if b['Id'] == word_id][0]\n",
    "                                            # Append the text of the word to the key\n",
    "                                            key += word.get('Text', '') + ' '\n",
    "                            # Remove trailing whitespace and add the key to the key_value dictionary\n",
    "                            key_value['Key'] = key.strip()\n",
    "                            \n",
    "                        # Extract values\n",
    "                        elif 'VALUE' in block['EntityTypes']:\n",
    "                            value = ''  # String to hold the value\n",
    "                            # Check if block has relationships\n",
    "                            if 'Relationships' in block:\n",
    "                                # Loop over each relationship\n",
    "                                for relationship in block['Relationships']:\n",
    "                                    # Check if the relationship is of type 'CHILD'\n",
    "                                    if relationship['Type'] == 'CHILD':\n",
    "                                        # Loop over each ID in the relationship\n",
    "                                        for word_id in relationship['Ids']:\n",
    "                                            # Find the block with the matching ID\n",
    "                                            word = [b for b in response['Blocks'] if b['Id'] == word_id][0]\n",
    "                                            # Append the text of the word to the value\n",
    "                                            value += word.get('Text', '') + ' '\n",
    "                            # Remove trailing whitespace and add the value to the key_value dictionary\n",
    "                            key_value['Value'] = value.strip()\n",
    "                            \n",
    "                    # Add the key-value pair to the forms list if it contains data\n",
    "                    if key_value:  \n",
    "                        forms.append(key_value)\n",
    "                        \n",
    "                # Extract signatures\n",
    "                elif block_type == 'SELECTION_ELEMENT':\n",
    "                    if 'SelectionStatus' in block:\n",
    "                        if block['SelectionStatus'] == 'SELECTED':\n",
    "                            # Add the bounding box of the signature to the signatures list\n",
    "                            signatures.append(block['Geometry']['BoundingBox'])\n",
    "                \n",
    "                # Extract lines\n",
    "                elif block_type == 'LINE':\n",
    "                    # Append a tuple of the line text and its bounding box top position\n",
    "                    lines.append((block['Text'], block['Geometry']['BoundingBox']['Top']))\n",
    "\n",
    "                # Extract words\n",
    "                elif block_type == 'WORD':\n",
    "                    # Append a tuple of the word text and its bounding box top position\n",
    "                    words.append((block['Text'], block['Geometry']['BoundingBox']['Top']))\n",
    "                    \n",
    "        return tables, forms, signatures, lines, words\n",
    "\n",
    "    def _extract_cell_data(self, cell_block, response):\n",
    "        \"\"\"\n",
    "        Helper method to extract cell data from a cell block.\n",
    "        \"\"\"\n",
    "        # Initialize a dictionary to hold the cell data\n",
    "        cell = {\"RowIndex\": cell_block['RowIndex'], \"ColumnIndex\": cell_block['ColumnIndex'], \"Text\": \"\"}\n",
    "        # Check if the cell block has relationships\n",
    "        if 'Relationships' in cell_block:\n",
    "            # Loop over each relationship in the cell block\n",
    "            for relationship in cell_block['Relationships']:\n",
    "                # Check if the relationship is of type 'CHILD'\n",
    "                if relationship['Type'] == 'CHILD':\n",
    "                    # Loop over each ID in the relationship\n",
    "                    for word_id in relationship['Ids']:\n",
    "                        # Find the block with the matching ID\n",
    "                        word_block = [b for b in response['Blocks'] if b['Id'] == word_id][0]\n",
    "                        # Append the text of the word to the cell's text\n",
    "                        cell['Text'] += word_block.get('Text', '') + ' '\n",
    "        # Remove trailing whitespace from the cell's text\n",
    "        cell['Text'] = cell['Text'].strip()\n",
    "        return cell\n",
    "\n",
    "    def tables_to_excel(self, tables, file_name):\n",
    "        \"\"\"\n",
    "        Save extracted tables to an Excel file.\n",
    "        \"\"\"\n",
    "        # Open an ExcelWriter object\n",
    "        with pd.ExcelWriter(file_name) as writer:\n",
    "            # Loop over each table in the tables list\n",
    "            for i, table_data in enumerate(tables):\n",
    "                # Find the maximum row and column indices to determine the size of the DataFrame\n",
    "                max_row_index = max(cell['RowIndex'] for cell in table_data['Cells'])\n",
    "                max_col_index = max(cell['ColumnIndex'] for cell in table_data['Cells'])\n",
    "\n",
    "                # Create an empty DataFrame with the appropriate size\n",
    "                df = pd.DataFrame('', index=range(1, max_row_index + 1), columns=range(1, max_col_index + 1))\n",
    "\n",
    "                # Fill the DataFrame with the cell data\n",
    "                for cell in table_data['Cells']:\n",
    "                    df.at[cell['RowIndex'], cell['ColumnIndex']] = cell['Text']\n",
    "\n",
    "                # Write the DataFrame to the Excel file\n",
    "                df.to_excel(writer, sheet_name=f'Table {i}')\n",
    "\n",
    "    def forms_to_df(self, forms):\n",
    "        \"\"\"\n",
    "        Convert extracted forms to a DataFrame.\n",
    "        \"\"\"\n",
    "        # Dictionary to hold the keys and values\n",
    "        forms_dict = {}\n",
    "\n",
    "        # Variable to hold the current key\n",
    "        current_key = None\n",
    "\n",
    "        # Iterate over each dictionary in the forms list\n",
    "        for form in forms:\n",
    "            # Check if 'Key' is in the dictionary\n",
    "            if 'Key' in form:\n",
    "                # Store the key in current_key variable\n",
    "                current_key = form['Key']\n",
    "            # Check if 'Value' is in the dictionary\n",
    "            elif 'Value' in form:\n",
    "                # Add the value to the forms_dict under the current key\n",
    "                forms_dict[current_key] = form['Value']\n",
    "\n",
    "        # Convert the forms_dict into a dataframe and transpose it for better view\n",
    "        df = pd.DataFrame(forms_dict, index=[0]).T.reset_index()\n",
    "\n",
    "        # Rename the columns to 'Key' and 'Value'\n",
    "        df.columns = ['Key', 'Value']\n",
    "\n",
    "        # Return the dataframe\n",
    "        return df\n",
    "\n",
    "    def process_document(self, document):\n",
    "        \"\"\"\n",
    "        Method to process a document.\n",
    "        Process here means analyzing the document using Textract,\n",
    "        and then extracting the useful information (tables, forms, signatures)\n",
    "        from the response.\n",
    "        \"\"\"\n",
    "        document.ocr_responses = self.analyze_document(document)  # Analyze the document\n",
    "        extracted_data = self.extract_data(document.ocr_responses)  # Extract the data from the analysis response\n",
    "        document.tables = extracted_data[0]  # Assign the extracted tables to the document instance\n",
    "        document.forms = self.forms_to_df(extracted_data[1])  # Assign the extracted forms to the document instance\n",
    "        document.signatures = extracted_data[2]  # Assign the extracted signatures to the document instance\n",
    "        document.lines = self.group_and_order_text(extracted_data[3])  # Group and order the lines\n",
    "        document.words = self.group_and_order_text(extracted_data[4])  # Group and order the words\n",
    "        return document  # Return the document\n",
    "\n",
    "    def process_documents(self, documents):\n",
    "        \"\"\"\n",
    "        Method to process multiple documents.\n",
    "        \"\"\"\n",
    "        processed_documents = []  # List to store the processed documents\n",
    "        for document in documents:  # For each document in the list\n",
    "            try:\n",
    "                processed_document = self.process_document(document)  # Try to process the document\n",
    "                processed_documents.append(processed_document)  # If successful, append the processed document to \n",
    "                                                                # the list\n",
    "            except ValueError as e:  # If a ValueError is raised in process_document\n",
    "                print(e)  # Print the error message\n",
    "        return processed_documents  # Return the list of processed documents\n",
    "    \n",
    "    def group_and_order_text(self, text_data):\n",
    "        \"\"\"\n",
    "        Group and order lines or words by their top position.\n",
    "        \"\"\"\n",
    "        # Sort the text data by the top position\n",
    "        sorted_text_data = sorted(text_data, key=lambda x: x[1])\n",
    "\n",
    "        # Initialize the first group with the first element\n",
    "        groups = [[sorted_text_data[0]]]\n",
    "\n",
    "        # Group the elements\n",
    "        for i in range(1, len(sorted_text_data)):\n",
    "            # If the top position of the current element is close to the last element of the last group, add it to the group\n",
    "            if abs(sorted_text_data[i][1] - groups[-1][-1][1]) < 0.01:  # Adjust the threshold as needed\n",
    "                groups[-1].append(sorted_text_data[i])\n",
    "            # Otherwise, start a new group with the current element\n",
    "            else:\n",
    "                groups.append([sorted_text_data[i]])\n",
    "\n",
    "        # Convert the groups to strings of text\n",
    "        grouped_text = [' '.join([word for word, _ in group]) for group in groups]\n",
    "\n",
    "        return grouped_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.Document at 0x7f32d2880f10>,\n",
       " <__main__.Document at 0x7f32d2880fa0>,\n",
       " <__main__.Document at 0x7f32d2880f40>,\n",
       " <__main__.Document at 0x7f32d2880e50>,\n",
       " <__main__.Document at 0x7f32d2880f70>,\n",
       " <__main__.Document at 0x7f32d2880dc0>,\n",
       " <__main__.Document at 0x7f32d2880ca0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor = DocumentProcessor()\n",
    "\n",
    "# Process a batch of documents\n",
    "documents = processor.get_bucket_folder_content('orders/4969182449/')\n",
    "processor.process_documents(documents)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents[0] is the first document in the folder of the order:4969182449\n",
    "\n",
    "#accessing raw text extracted from the doc\n",
    "lines = documents[0].lines\n",
    "\n",
    "#accessing forms extracted from the doc as a dataframe of two columns (Keys and Values)\n",
    "forms = documents[0].forms\n",
    "\n",
    "#accessing signatures extracted from the doc\n",
    "signatures = documents[0].signatures\n",
    "\n",
    "#accessing tables extracted from the doc\n",
    "tables = documents[0].tables\n",
    "\n",
    "#converting the tables extractaed to an excel format and saving them\n",
    "processor.tables_to_excel(tables, \"DUM_table.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CERTIFICAT DE CIRCULATION DES MARCHANDISES',\n",
       " '1. Exportateur (nom agresse complete. pays) EUR.1 N° A 8003927',\n",
       " 'TARGANINE',\n",
       " 'N°33 BLOC 3 RUE DE MARRAKECH QI AGADIR Consulter les notes ao verso avant de remplir le formulaire',\n",
       " '2. Certificat utilisé dans les échanges préférentiels entre',\n",
       " 'LE ROYAUME DU MAROC 3. Destinataire (nom, agresse complète. pays) (mention facultative',\n",
       " 'et',\n",
       " 'UE BASF Beauty Care',\n",
       " 'FRANCE',\n",
       " 'undiquer les pavs groupes de pays ou territoires concernes)',\n",
       " '5. Pays. groupe de pays ou 4. Pays. groupe de pays ou',\n",
       " 'territoire de destination territoire dont les produits',\n",
       " 'sont consideres comme FRANCE originaires, MAROC',\n",
       " '6. Informations relatives ou transport (mention facultative] 7. Observations',\n",
       " \"8. N° d'ordre. marques. numéros, nombre et nature des colis (1). désignation des 10. Factures 9. Masse brute marchandises (mention (kg) ou autre facultative) mesure\",\n",
       " 'adique 4 1, m ², etc 1 numbre doom',\n",
       " 'ME60/22 8685.000 9 COLIS',\n",
       " \"9000 L HUILE D'ARGAN KG 15/02/2022\",\n",
       " \"12. DÉCLARATION DE L'EXPORTATEUR 11. VISA DE LA DOUANE\",\n",
       " 'Je soussigné declare que les marchandises Déclaration certifiee conforme',\n",
       " \"désignées ci-dessus remplissent les condi- Document d'exportation (2) :\",\n",
       " \"tions requises pour l'obtention du présent n° Modele errore certificat. 41106020220002370 DUM - du 2% Bureau de douane\",\n",
       " 'MINISTRY Pays ou territoire de delivrance Importation LE ROYAUME.DU AAROC FAUME le A A le DU 19/02/2022 Port de Tangér- Port de Tanger- 23/02/2022',\n",
       " \"(Signature) L'authenticité de certificat peut être vérifiée via le lien : (Signature)\",\n",
       " 'hitpall tificat',\n",
       " 'Scanné avec CamScanner']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3. Destinataire (nom, agresse complète. pays) ...</td>\n",
       "      <td>BASF Beauty Care FRANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7. Observations</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6. Informations relatives ou transport (mentio...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. Exportateur (nom agresse complete. pays)</td>\n",
       "      <td>TARGANINE N°33 BLOC 3 RUE DE MARRAKECH QI AGADIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4. Pays. groupe de pays ou territoire dont les...</td>\n",
       "      <td>MAROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5. Pays. groupe de pays ou territoire de desti...</td>\n",
       "      <td>FRANCE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bureau de douane</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2. Certificat utilisé dans les échanges préfér...</td>\n",
       "      <td>LE ROYAUME DU MAROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pays ou territoire de delivrance</td>\n",
       "      <td>LE ROYAUME.DU AAROC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Port de Tangér-</td>\n",
       "      <td>19/02/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Document d'exportation (2) :</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>du</td>\n",
       "      <td>DUM 41106020220002370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Modele</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Port de Tanger-</td>\n",
       "      <td>23/02/2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Déclaration certifiee conforme</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>n°</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>(Signature)</td>\n",
       "      <td>L'authenticité de certificat peut être vérifié...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Key  \\\n",
       "0   3. Destinataire (nom, agresse complète. pays) ...   \n",
       "1                                     7. Observations   \n",
       "2   6. Informations relatives ou transport (mentio...   \n",
       "3         1. Exportateur (nom agresse complete. pays)   \n",
       "4   4. Pays. groupe de pays ou territoire dont les...   \n",
       "5   5. Pays. groupe de pays ou territoire de desti...   \n",
       "6                                    Bureau de douane   \n",
       "7   2. Certificat utilisé dans les échanges préfér...   \n",
       "8                    Pays ou territoire de delivrance   \n",
       "9                                     Port de Tangér-   \n",
       "10                       Document d'exportation (2) :   \n",
       "11                                                 du   \n",
       "12                                             Modele   \n",
       "13                                    Port de Tanger-   \n",
       "14                     Déclaration certifiee conforme   \n",
       "15                                                 n°   \n",
       "16                                        (Signature)   \n",
       "\n",
       "                                                Value  \n",
       "0                             BASF Beauty Care FRANCE  \n",
       "1                                                      \n",
       "2                                                      \n",
       "3    TARGANINE N°33 BLOC 3 RUE DE MARRAKECH QI AGADIR  \n",
       "4                                               MAROC  \n",
       "5                                              FRANCE  \n",
       "6                                                      \n",
       "7                                 LE ROYAUME DU MAROC  \n",
       "8                                 LE ROYAUME.DU AAROC  \n",
       "9                                          19/02/2022  \n",
       "10                                                     \n",
       "11                              DUM 41106020220002370  \n",
       "12                                                     \n",
       "13                                         23/02/2022  \n",
       "14                                                     \n",
       "15                                                     \n",
       "16  L'authenticité de certificat peut être vérifié...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Cells': [{'RowIndex': 1,\n",
       "    'ColumnIndex': 1,\n",
       "    'Text': \"8. N° d'ordre. marques. numéros, nombre et nature des colis (1). désignation des marchandises\"},\n",
       "   {'RowIndex': 1,\n",
       "    'ColumnIndex': 2,\n",
       "    'Text': '9. Masse brute (kg) ou autre mesure 1, m ², etc 1'},\n",
       "   {'RowIndex': 1,\n",
       "    'ColumnIndex': 3,\n",
       "    'Text': '10. Factures (mention facultative)'},\n",
       "   {'RowIndex': 2, 'ColumnIndex': 1, 'Text': \"9 COLIS 9000 L HUILE D'ARGAN\"},\n",
       "   {'RowIndex': 2, 'ColumnIndex': 2, 'Text': '8685.000 KG'},\n",
       "   {'RowIndex': 2, 'ColumnIndex': 3, 'Text': 'ME60/22 15/02/2022'}]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
